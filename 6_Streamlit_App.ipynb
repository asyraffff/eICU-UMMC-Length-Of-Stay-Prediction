{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asyraffff/eICU-UMMC-Length-Of-Stay-Prediction/blob/main/6_Streamlit_App.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e3wSKYHXbYP",
        "outputId": "7dd82c01-2aa5-472d-eb72-9dc33349149d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-olodtweZUrN"
      },
      "outputs": [],
      "source": [
        "!pip install -q streamlit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiR1mpu_wa2m",
        "outputId": "46d734eb-0360-41ba-9ca6-90f031c9766a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: shap in /usr/local/lib/python3.10/dist-packages (0.44.0)\n",
            "Requirement already satisfied: streamlit-shap in /usr/local/lib/python3.10/dist-packages (1.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from shap) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from shap) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from shap) (1.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from shap) (1.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.10/dist-packages (from shap) (4.66.1)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.10/dist-packages (from shap) (23.2)\n",
            "Requirement already satisfied: slicer==0.0.7 in /usr/local/lib/python3.10/dist-packages (from shap) (0.0.7)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from shap) (0.58.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from shap) (2.2.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->shap) (0.41.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2023.3.post1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (3.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->shap) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install shap streamlit-shap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dn2_feUnGNeO",
        "outputId": "07d11b05-c8fa-4706-d57b-08fc44000309"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "import shap\n",
        "from streamlit_shap import st_shap\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "\n",
        "# Load the saved model\n",
        "dbn_model = tf.keras.models.load_model('drive/My Drive/FYP_LOS/dataset/dbn_model.h5')\n",
        "\n",
        "st.title('Length of Stay Prediction for Cardiac Patient at UMMC')\n",
        "\n",
        "if 'random_patient' not in st.session_state:\n",
        "    st.session_state.random_patient = 0\n",
        "\n",
        "if 'data' not in st.session_state:\n",
        "    st.session_state.data = pd.read_csv(\"drive/My Drive/FYP_LOS/dataset/cardiac_ed_ppum_viva.csv\", low_memory=False)\n",
        "\n",
        "with open(\"drive/My Drive/FYP_LOS/dataset/dl_scaler.pkl\", 'rb') as file:\n",
        "    scaler = pickle.load(file)\n",
        "\n",
        "patientID = st.selectbox(\n",
        "    'Choose Patient ID',\n",
        "    (0, 1, 2, 3, 4, 5, 6, 7, 8),\n",
        "    index=st.session_state.random_patient)\n",
        "\n",
        "def randomize_patient():\n",
        "    st.session_state.random_patient = random.randint(0, 8)\n",
        "\n",
        "st.button('Pick random patient', on_click=randomize_patient)\n",
        "\n",
        "st.text(' ')\n",
        "st.write(\"<p style='text-align: justify;'>Patient information</p>\",\n",
        "            unsafe_allow_html=True)\n",
        "st.table(st.session_state.data.iloc[patientID])\n",
        "\n",
        "st.write(\"<p style='text-align: justify;'>Diagnosis code :</p>\",\n",
        "            unsafe_allow_html=True)\n",
        "st.markdown(\"**5** : Angina, unstable (angina interferes w/quality)\",\n",
        "            unsafe_allow_html=True)\n",
        "st.markdown(\"**47** : Infarction, acute myocardial (MI)\\nInfarction\",\n",
        "            unsafe_allow_html=True)\n",
        "st.text(\" \")\n",
        "\n",
        "# Function to preprocess the input data similar to what was done before training the model\n",
        "def preprocess_data(df):\n",
        "    # If 'df' is a Series (single row of data), convert it to a DataFrame\n",
        "    if isinstance(df, pd.Series):\n",
        "        df = pd.DataFrame(df).transpose()\n",
        "\n",
        "    # Create 'LOS_log' column with log-transformed LOS data\n",
        "    df['LOS_log'] = np.log1p(df['LOS'])\n",
        "\n",
        "    # Remove 'LOS' column\n",
        "    X = df.drop(['LOS', 'LOS_log'], axis=1)\n",
        "    st.session_state.columns = X.columns.tolist()\n",
        "\n",
        "    X_scaled = scaler.transform(X)\n",
        "    return X_scaled\n",
        "\n",
        "# Function to predict Length of Stay (LOS) for a given patient using the DBN model\n",
        "def predict_length_of_stay(patient_data):\n",
        "    preprocessed_data = preprocess_data(patient_data)\n",
        "    # Predict LOS using the loaded DBN model\n",
        "    predicted_los = dbn_model.predict(preprocessed_data)\n",
        "    return predicted_los\n",
        "\n",
        "# Update the 'predict' function to use the DBN model for predictions\n",
        "def predict():\n",
        "    patient_data = st.session_state.data.iloc[patientID]\n",
        "    predicted_los = predict_length_of_stay(patient_data)\n",
        "    st.session_state.predicted_los = np.expm1(predicted_los)\n",
        "\n",
        "st.button('Predict', on_click=predict)\n",
        "\n",
        "st.subheader('Prediction result')\n",
        "if 'predicted_los' in st.session_state:\n",
        "    st.text(f'LOS : {st.session_state.predicted_los[0][0]:.2f} days')\n",
        "\n",
        "if 'predicted_los' in st.session_state:\n",
        "    st.title('Explainable AI (Global Interpretation)')\n",
        "\n",
        "    st.markdown(\"A **global method** helps us understand the **overall structure** of **how a model makes a decision**.\",\n",
        "            unsafe_allow_html=True)\n",
        "\n",
        "    st.subheader('Summary Plot')\n",
        "\n",
        "    st.markdown(\"The `summary plot` shows the **most important features** and the **magnitude of their impact on the model**. It is the global interpretation\",\n",
        "            unsafe_allow_html=True)\n",
        "\n",
        "    # Create an explainer using the trained DBN model and the data\n",
        "    explainer = shap.DeepExplainer(dbn_model, preprocess_data(st.session_state.data))\n",
        "\n",
        "    # Calculate SHAP values for new data\n",
        "    shap_values = explainer.shap_values(preprocess_data(st.session_state.data))\n",
        "\n",
        "    # Visualize SHAP summary plot for feature importance\n",
        "    st_shap(shap.summary_plot(shap_values, features=preprocess_data(st.session_state.data),\n",
        "            feature_names=st.session_state.columns))\n",
        "\n",
        "    st.markdown(\"Passing a **matrix of SHAP values** to the bar plot function creates a **global feature importance plot**, where the global importance of each feature is taken to be the **mean absolute value** for that feature over all the given samples\",\n",
        "            unsafe_allow_html=True)\n",
        "\n",
        "    st.markdown(\"Here the **features** are **ordered** from the **highest to the lowest effect on the prediction**. It takes in account the **absolute SHAP value**, so it **does not matter** if the feature affects the prediction in a **positive or negative way**.\",\n",
        "            unsafe_allow_html=True)\n",
        "\n",
        "    st.subheader('Beeswarm Plot')\n",
        "\n",
        "    st.markdown(\"The `beeswarm plot` is designed to display an information-dense summary of **how the top features** in a dataset **impact the model’s output**. `Each instance` the given explanation is represented by a **single dot** on each feature row.\",\n",
        "            unsafe_allow_html=True)\n",
        "\n",
        "    st.markdown(\"The `x` position of the dot is determined by the **SHAP value** `(shap_values.value[instance,feature])` of that feature, and dots **“pile up”** along each feature row to show **density**.\",\n",
        "            unsafe_allow_html=True)\n",
        "\n",
        "    st.markdown(\"**Color** is used to display the **original value of a feature** `(shap_values.data[instance,feature])`.\",\n",
        "            unsafe_allow_html=True)\n",
        "\n",
        "    st_shap(shap.summary_plot(shap_values[0], features=preprocess_data(st.session_state.data),\n",
        "                              feature_names=st.session_state.columns))\n",
        "\n",
        "    st.markdown(\"In the plot above we can see that **high values** of the `intubated (1)` variable have a **high positive contribution** on the prediction, while **low values** have a **low positive contribution**.\",\n",
        "            unsafe_allow_html=True)\n",
        "\n",
        "    st.markdown(\"The `bun` variable has a really **high positive contribution** when its values are **high**, and a **low negative contribution** on **low values**.\",\n",
        "            unsafe_allow_html=True)\n",
        "\n",
        "    st.markdown(\"The feature `gender` has almost **no contribution** to the prediction, whether its values are high or low.\",\n",
        "            unsafe_allow_html=True)\n",
        "\n",
        "\n",
        "    st.title('Explainable AI (Local Interpretation)')\n",
        "\n",
        "    st.text(\"\")\n",
        "    st.subheader('Force Plot')\n",
        "\n",
        "    st.markdown(\"The `force plot` is another way to see the effect each feature has on the prediction, for a given observation.\",\n",
        "            unsafe_allow_html=True)\n",
        "\n",
        "    # Force plot\n",
        "    st_shap(shap.force_plot(explainer.expected_value[0].numpy(),\n",
        "                   shap_values[0][patientID],feature_names=st.session_state.columns,\n",
        "                   out_names=\"LOS\", figsize=(11,4), matplotlib=matplotlib))\n",
        "\n",
        "    st.markdown(\"In this plot the **positive SHAP values** are displayed on the **left** side and the **negative** on the **right** side, as if competing against each other.\",\n",
        "            unsafe_allow_html=True)\n",
        "\n",
        "    st.markdown(\"The **highlighted value** is the **prediction** for that observation.\",\n",
        "            unsafe_allow_html=True)\n",
        "\n",
        "    # st.text(\"\")\n",
        "    # st.subheader('Decision Plot')\n",
        "\n",
        "    # st.text(\"The decision plot makes it possible to observe the amplitude of each change,\")\n",
        "    # st.text(\"taken by a sample for the values of the displayed features.\")\n",
        "\n",
        "\n",
        "    # Decision plot\n",
        "    # st_shap(shap.decision_plot(explainer.expected_value[0].numpy(),\n",
        "                   # shap_values[0][patientID], features = preprocess_data(st.session_state.data),\n",
        "                   # feature_names = st.session_state.columns))\n",
        "\n",
        "    st.text(\"\")\n",
        "    st.subheader('Waterfall Plot')\n",
        "\n",
        "    st.markdown(\"`Waterfall plots` are designed to display explanations for individual predictions.\",\n",
        "            unsafe_allow_html=True)\n",
        "\n",
        "    st.markdown(\"The **bottom** of a waterfall plot starts as the **expected value** of the model output, and then each row shows how the **positive (red)** or **negative (blue)** contribution of each feature moves the value from the expected model output over the background dataset to the model output for this prediction.\",\n",
        "            unsafe_allow_html=True)\n",
        "\n",
        "    # Waterfall plot\n",
        "    st_shap(shap.plots._waterfall.waterfall_legacy(explainer.expected_value[0].numpy(),\n",
        "                                       shap_values[0][patientID], feature_names = st.session_state.columns))\n",
        "\n",
        "    st.markdown(\"1. **Expected Value (Top)**: The top of the plot represents the **model's expected value**. This is the **starting point** for the prediction.\",\n",
        "            unsafe_allow_html=True)\n",
        "\n",
        "    st.markdown(\"2. **Feature Contributions**: Each **horizontal bar** represents the **contribution** of a specific feature to the prediction.\",\n",
        "            unsafe_allow_html=True)\n",
        "\n",
        "    st.markdown(\"3. **Positive Contribution (+)**: If a bar extends to the **right** of the expected value, it indicates a **positive contribution**. For example, `hematocrit` has a positive contribution of `0.07`. This means that the **presence of hematocrit increases the model's prediction** by `0.07`.\",\n",
        "            unsafe_allow_html=True)\n",
        "\n",
        "    st.markdown(\"4. **Negative Contribution (-)**: If a bar extends to the **left** of the expected value, it indicates a **negative contribution**. For example, `intubated` has a negative contribution of `0.07`. This means that the **presence of intubated decreases the model's prediction** by `0.07`.\",\n",
        "            unsafe_allow_html=True)\n",
        "\n",
        "    st.markdown(\"5. **Cumulative Sum**: As you **move down** the plot, the contributions are **added** to the cumulative sum.\",\n",
        "            unsafe_allow_html=True)\n",
        "\n",
        "    st.markdown(\"6. **Final Prediction**: The **final position** on the plot represents the **model's prediction** for the specific instance.\",\n",
        "            unsafe_allow_html=True)\n",
        "\n",
        "    st.markdown(\"In summary, **positive contributions push the prediction higher**, and **negative contributions pull it lower**. The waterfall plot provides a clear visual representation of how each feature's contribution combines to form the model's prediction for a specific instance.\",\n",
        "            unsafe_allow_html=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCoGHapCZ2DH",
        "outputId": "a5af400b-8460-41bc-da80-fb6216715ce1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25h\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35msaveError\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35menoent\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No description\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No repository field.\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No README data\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No license field.\n",
            "\u001b[0m\n",
            "+ localtunnel@2.0.2\n",
            "updated 1 package and audited 36 packages in 0.601s\n",
            "\n",
            "3 packages are looking for funding\n",
            "  run `npm fund` for details\n",
            "\n",
            "found 2 \u001b[93mmoderate\u001b[0m severity vulnerabilities\n",
            "  run `npm audit fix` to fix them, or `npm audit` for details\n",
            "\u001b[K\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!npm install localtunnel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3sxz2ZfxZ4JM"
      },
      "outputs": [],
      "source": [
        "!streamlit run app.py --server.address=localhost &>/content/logs.txt &"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNbvvjx9ay7I",
        "outputId": "6953e59e-1775-444d-fc40-e786b8bcab53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Password/Enpoint IP for localtunnel is: 35.199.154.13\n"
          ]
        }
      ],
      "source": [
        "import urllib\n",
        "print(\"Password/Enpoint IP for localtunnel is:\",urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip(\"\\n\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kU_rU1VrZ6Ow",
        "outputId": "79025760-d569-40de-d7a3-aa442176c7ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25hnpx: installed 22 in 3.152s\n",
            "your url is: https://cuddly-weeks-leave.loca.lt\n"
          ]
        }
      ],
      "source": [
        "!npx localtunnel --port 8501"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOa/qqL6186GGzt4o5lTB6P",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}